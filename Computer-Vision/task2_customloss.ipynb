{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sbXQcIZzBw_"
   },
   "source": [
    "# **Task 2 - Custom Loss**\n",
    "**Vision Transformer (ViT) Baseline**\n",
    "\n",
    "**Authors:** Iris Vukovic & Olmo Gordon Rodriguez\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3MgKQVLd2-_"
   },
   "source": [
    "## Downloading the APPA-REAL dataset\n",
    "In this case, we are using the full dataset (not its reduced version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvIKRd9Pc-WB",
    "outputId": "8b8d6e63-4c0a-40ce-d5b2-238e280d1e95"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# downloading the data\n",
    "!wget http://data.chalearnlap.cvc.uab.cat/Colab_MFPDS/2025/appa-real-dataset_v2.zip\n",
    "\n",
    "with ZipFile('appa-real-dataset_v2.zip','r') as zip_ref:\n",
    "   zip_ref.extractall()\n",
    "   print('Data decompressed successfully')\n",
    "\n",
    "# removing the .zip file after extraction to clean space\n",
    "!rm appa-real-dataset_v2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4QDmsG0eWJp"
   },
   "source": [
    "## Check pytorch version\n",
    " - This notebook was successfully tested on version = 2.5.1+cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxVPG7QBeYqk",
    "outputId": "619313d7-7c0b-49b2-aa89-61d8d3d3c11c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eigRTWA3LmlF",
    "outputId": "f91e5ce2-6ec4-48ba-8f17-8af7e3cabc36"
   },
   "outputs": [],
   "source": [
    "# installing torchinfo to print model summary\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65fh0wFgwuEi"
   },
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnnakGTv2qjM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "from timm import create_model\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqjgWciLeFZU"
   },
   "source": [
    "# Defining the data loader class\n",
    "In this example, metadata information is loaded but not used. Future implementations can take benefit of it.\n",
    "Note that age labels are divided by 100 (assuming 100 is the max age found in the dataset) so that the age values can be normalized to be in the range of 0 and 1. This way, we can add a sigmoid activation in the last layer of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sjEEsFbEoF_"
   },
   "outputs": [],
   "source": [
    "class AgeEstimationDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.age_normalization_factor = 100; # used to normalize age labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __normalization_factor__(self):\n",
    "        return self.age_normalization_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = f\"{self.data_info.iloc[idx, 0]:06d}.jpg\"  # Format image ID\n",
    "        image_path = os.path.join(self.image_dir, image_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\n",
    "        # normalizing age labes (by 100) to be between 0 and 1 (assuming 100 is the max age)\n",
    "        age = float(self.data_info.iloc[idx, 1])/self.age_normalization_factor  # Load age label\n",
    "        metadata = self.data_info.iloc[idx, 2:].tolist()  # Extract metadata as list\n",
    "        ethnicity = self.data_info.iloc[idx, 2]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(age, dtype=torch.float32), metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2EWwi56E9Fm"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOY3UdoA690u",
    "outputId": "3def6098-19d2-40c0-e72e-4d3314ff04d1"
   },
   "outputs": [],
   "source": [
    "# Create dataset and dataloader (train set):\n",
    "dataset_train = AgeEstimationDataset(\"train_data\", \"labels_metadata_train.csv\", transform=data_transforms)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of train samples: {len(dataloader_train.dataset)}\")\n",
    "\n",
    "# Create dataset and dataloader (validation set):\n",
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of valid samples: {len(dataloader_valid.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "j7ZrqqobHj-Q",
    "outputId": "6eb15ea8-04f1-4160-e4ad-f0af76617d55"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to display image samples\n",
    "def display_samples(dataset, num_samples=3):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(11, 5))\n",
    "    for i in range(num_samples):\n",
    "        random_index = random.randint(0, len(dataset) - 1)\n",
    "        image, age, metadata = dataset[random_index]\n",
    "\n",
    "        image = image * np.array([0.5]) + np.array([0.5])  # Denormalize\n",
    "        image = image.permute(1, 2, 0).numpy() if isinstance(image, torch.Tensor) else np.array(image)\n",
    "\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis(\"off\")\n",
    "        # denormalizing the age values to plot the original labels\n",
    "        axes[i].set_title(f\"Age: {age*dataset.__normalization_factor__():.2f}\\n{', '.join(metadata)}\")\n",
    "    plt.show()\n",
    "\n",
    "display_samples(dataset_train, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "-l0fzjeo2wkW",
    "outputId": "19473a30-c992-4ea9-9a7e-a7375d29df30"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the updated CSV file\n",
    "df = pd.read_csv(\"labels_metadata_train.csv\")\n",
    "\n",
    "# Plot the age distribution using a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['age'], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "sdlDhvc13WkZ",
    "outputId": "d745bacb-bab8-448e-aa22-bfb941f4bfe1"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of Ethnicity (as an example of metadata)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ethnicity_valid_values = ['asian', 'caucasian', 'afroamerican']\n",
    "df = df[df['ethnicity'].isin(ethnicity_valid_values)]\n",
    "ethnicity_counts = df['ethnicity'].value_counts()\n",
    "plt.bar(ethnicity_counts.index, ethnicity_counts.values, color='orange', alpha=0.7)\n",
    "plt.title('Ethnicity Distribution')\n",
    "plt.xlabel('Ethnicity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "IyJK7I3R3YkF",
    "outputId": "7e0cd152-8df6-45ed-d324-1557ff1e7fa1"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of Gender (another example of metadata)\n",
    "df = pd.read_csv(\"labels_metadata_train.csv\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "gender_valid_values = ['male', 'female']\n",
    "df = df[df['gender'].isin(gender_valid_values)]\n",
    "gender_counts = df['gender'].value_counts()\n",
    "plt.bar(gender_counts.index, gender_counts.values, color='green', alpha=0.7)\n",
    "plt.title('Gender Distribution')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "BOmi5CCb3bAS",
    "outputId": "44dc709e-655e-4e11-f7b9-abbbe74a2417"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of Expression (another example of metadata)\n",
    "df = pd.read_csv(\"labels_metadata_train.csv\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "expression_valid_values = ['slightlyhappy', 'happy', 'neutral' , 'other']\n",
    "df = df[df['emotion'].isin(expression_valid_values)]\n",
    "expression_counts = df['emotion'].value_counts()\n",
    "plt.bar(expression_counts.index, expression_counts.values, color='red', alpha=0.7)\n",
    "plt.title('Expression Distribution')\n",
    "plt.xlabel('Expression')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjlySHHyCn4t"
   },
   "source": [
    "#Augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xg4zn0yuo_Fj",
    "outputId": "25666760-41a6-47a2-9b8c-347a087f6451"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm  # for progress bar (optional)\n",
    "import torch\n",
    "\n",
    "class AgeEstimationDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None, augmentation_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.augmentation_transform = augmentation_transform  # Optional augmentation transform\n",
    "        self.age_normalization_factor = 100  # Used to normalize age labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __normalization_factor__(self):\n",
    "        return self.age_normalization_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = f\"{self.data_info.iloc[idx, 0]:06d}.jpg\"  # Format image ID\n",
    "        image_path = os.path.join(self.image_dir, image_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\n",
    "        # Normalize age labels (by 100) to be between 0 and 1 (assuming 100 is the max age)\n",
    "        age = float(self.data_info.iloc[idx, 1]) / self.age_normalization_factor  # Load age label\n",
    "        metadata = self.data_info.iloc[idx, 2:].tolist()  # Extract metadata as list\n",
    "        ethnicity = metadata[1]\n",
    "        age_value = int(self.data_info.iloc[idx, 1])\n",
    "\n",
    "        # Apply augmentation based on conditions (ethnicity or age > 60)\n",
    "        if (ethnicity in ['afroamerican', 'asian']) or (age_value > 60):\n",
    "            if self.augmentation_transform:\n",
    "                image = self.augmentation_transform(image)\n",
    "\n",
    "        # Apply any additional transforms (like normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(age, dtype=torch.float32), metadata\n",
    "\n",
    "\n",
    "def save_augmented_images_and_update_csv(dataset, augmentation_transforms, output_dir, csv_file, num_augmented_images=3):\n",
    "    # Create a new directory for augmented images\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the original CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "    # Augment and save images\n",
    "    augmented_data = []\n",
    "    for idx in tqdm(range(len(dataset)), desc=\"Processing images\"):\n",
    "        image, age, metadata = dataset[idx]  # Get the original image and other data\n",
    "        original_image_id = dataset.data_info.iloc[idx, 0]\n",
    "        metadata = dataset.data_info.iloc[idx, 2:].tolist()\n",
    "        gender = metadata[0]\n",
    "        ethnicity = metadata[1]\n",
    "        expression = metadata[2]\n",
    "        age_value = int(dataset.data_info.iloc[idx, 1])\n",
    "\n",
    "        # Apply augmentation only if the condition is met (ethnicity or age > 60)\n",
    "        if (ethnicity in ['afroamerican', 'asian']) or (age_value > 60):\n",
    "            # Apply augmentation multiple times (num_augmented_images times)\n",
    "            for i in range(num_augmented_images):\n",
    "                augmented_image = augmentation_transforms(image)  # Apply the augmentation\n",
    "\n",
    "                augmented_image_pil = transforms.ToPILImage()(augmented_image)\n",
    "\n",
    "                # Save the augmented image\n",
    "                augmented_image_name = f\"augmented_{original_image_id}_{i}.jpg\"\n",
    "                new_image_path = os.path.join(output_dir, augmented_image_name)\n",
    "                augmented_image_pil.save(new_image_path)\n",
    "\n",
    "                # Add new entry to augmented data\n",
    "                #augmented_data.append([original_image_id, age.item()] + [metadata] + [new_image_path])\n",
    "                augmented_data.append([original_image_id, age.item()*100, gender, ethnicity, expression])\n",
    "\n",
    "\n",
    "    # Append the augmented data to the original dataframe\n",
    "    augmented_df = pd.DataFrame(augmented_data, columns=df.columns.tolist())\n",
    "\n",
    "    # Append to the original CSV file without overwriting it\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "    else:\n",
    "        # If file exists, append to a new file to avoid overwriting\n",
    "        new_csv_file = f\"augmented_{os.path.basename(csv_file)}\"\n",
    "        df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "        df.to_csv(new_csv_file, index=False)\n",
    "        print(f\"CSV file already exists. Augmented data saved to new file: {new_csv_file}\")\n",
    "\n",
    "    print(f\"CSV file updated with augmented images: {csv_file}\")\n",
    "\n",
    "\n",
    "# Define the augmentation transforms\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "])\n",
    "\n",
    "# Define the standard transforms for all data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Assume the original dataset and transform\n",
    "dataset_train = AgeEstimationDataset(\n",
    "    image_dir=\"train_data\",  # Directory where original images are stored\n",
    "    csv_file=\"labels_metadata_train.csv\",  # Original CSV file\n",
    "    transform=data_transforms['train'],  # You can apply the transforms to training data here\n",
    "    augmentation_transform=None  # Augmentation transform will be applied conditionally in the `__getitem__` method\n",
    ")\n",
    "\n",
    "# Directory to save augmented images\n",
    "output_dir = \"augmented_train_data\"\n",
    "\n",
    "# Number of augmented images to generate per original image\n",
    "num_augmented_images = 3  # For example, generate 3 augmented images for each original image\n",
    "\n",
    "# Update CSV with augmented images\n",
    "save_augmented_images_and_update_csv(dataset_train, augmentation_transforms, output_dir, \"labels_metadata_train.csv\", num_augmented_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWiJw2_dGKtw",
    "outputId": "9cdae301-7dfa-453a-b490-a12f0917c892"
   },
   "outputs": [],
   "source": [
    "# Create dataset and dataloader (train set):\n",
    "aug_dataset_train = AgeEstimationDataset(\"train_data\", \"augmented_labels_metadata_train.csv\", transform=data_transforms['train'])\n",
    "aug_dataloader_train = DataLoader(aug_dataset_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of train samples: {len(aug_dataloader_train.dataset)}\")\n",
    "\n",
    "# Create dataset and dataloader (validation set):\n",
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms['val'])\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of valid samples: {len(dataloader_valid.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "z2W2kmJduaa3",
    "outputId": "7f4471df-87e5-4964-cc75-a464727c5cc9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to denormalize images for visualization\n",
    "def denormalize(tensor):\n",
    "    mean = [0.5]\n",
    "    std = [0.5]\n",
    "    tensor = tensor * std[0] + mean[0]\n",
    "    tensor = tensor.clip(0, 1)\n",
    "    return tensor\n",
    "\n",
    "# Select a random sample from the dataset\n",
    "random_idx = random.randint(0, len(dataset_train) - 1)\n",
    "image, _, _ = dataset_train[random_idx]  # Get the image at the random index\n",
    "\n",
    "# Apply the augmentation transforms to the image\n",
    "augmented_images = []\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "])\n",
    "\n",
    "# Generate augmented versions of the random image\n",
    "for _ in range(5):  # Generate 5 augmented versions\n",
    "    augmented_image = augmentation_transforms(image)  # Apply the augmentations\n",
    "    augmented_images.append(augmented_image)\n",
    "\n",
    "# Convert image tensors to numpy arrays for plotting\n",
    "image = denormalize(image).numpy().transpose(1, 2, 0)  # Convert from (C, H, W) to (H, W, C)\n",
    "augmented_images = [denormalize(img).numpy().transpose(1, 2, 0) for img in augmented_images]\n",
    "\n",
    "# Plot the original image and its augmented versions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 6, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Plot the augmented images\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 6, i + 2)\n",
    "    plt.imshow(augmented_images[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Augmented {i+1}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTa4g4uZ7miZ"
   },
   "outputs": [],
   "source": [
    "def display_samples(dataset, num_samples=4):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image, age, metadata = dataset[i]  # Get the image and metadata\n",
    "        image = image.numpy().transpose((1, 2, 0))  # Convert tensor to numpy array (H, W, C)\n",
    "\n",
    "        # Denormalize the image (assuming the original image was normalized between -1 and 1)\n",
    "        image = image * np.array([0.5]) + np.array([0.5])  # Denormalize\n",
    "\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "        # Ensure metadata is properly converted to strings\n",
    "        metadata_str = [str(m) for m in metadata]  # Convert all metadata to strings\n",
    "\n",
    "        # Display age and metadata\n",
    "        axes[i].set_title(f\"Age: {age * dataset.__normalization_factor__():.2f}\\n{', '.join(metadata_str)}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "toFoTXj_3mC5",
    "outputId": "17d1df7a-93f6-4d11-9743-35990b5392f5"
   },
   "outputs": [],
   "source": [
    "display_samples(aug_dataset_train, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "kliOHYOh7Ibo",
    "outputId": "7088e0f7-aa21-4cf2-a8ae-3ad02ea44628"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the updated CSV file\n",
    "df = pd.read_csv(\"augmented_labels_metadata_train.csv\")\n",
    "\n",
    "# Plot the age distribution using a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['age'], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Age Distribution after augmenting')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "UJUfinib7NLU",
    "outputId": "2c910afa-c65f-4042-cd38-22e18d0c403b"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of Ethnicity (as an example of metadata)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ethnicity_valid_values = ['asian', 'caucasian', 'afroamerican']\n",
    "df = df[df['ethnicity'].isin(ethnicity_valid_values)]\n",
    "ethnicity_counts = df['ethnicity'].value_counts()\n",
    "plt.bar(ethnicity_counts.index, ethnicity_counts.values, color='orange', alpha=0.7)\n",
    "plt.title('Ethnicity Distribution after augmenting')\n",
    "plt.xlabel('Ethnicity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "ZavZcxT6DOMq",
    "outputId": "a881aa8d-efca-4e84-8137-60880a7c6029"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of gender (as an example of metadata)\n",
    "df = pd.read_csv(\"augmented_labels_metadata_train.csv\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "gender_valid_values = ['female', 'male']\n",
    "df = df[df['gender'].isin(gender_valid_values)]\n",
    "gender_counts = df['gender'].value_counts()\n",
    "plt.bar(gender_counts.index, gender_counts.values, color='green', alpha=0.7)\n",
    "plt.title('Gender Distribution after augmenting')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "MP4WGA-7DanA",
    "outputId": "45220c95-8b4f-4e2d-8d32-8ee8a9e21e64"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of emotion (as an example of metadata)\n",
    "plt.figure(figsize=(10, 6))\n",
    "emotion_valid_values = ['slightlyhappy', 'happy', 'neutral', 'other']\n",
    "df = df[df['emotion'].isin(emotion_valid_values)]\n",
    "emotion_counts = df['emotion'].value_counts()\n",
    "plt.bar(emotion_counts.index, emotion_counts.values, color='red', alpha=0.7)\n",
    "plt.title('Emotion Distribution after augmenting')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCIi_-JZ20rE"
   },
   "outputs": [],
   "source": [
    "# Vision Transformer Model for Age Prediction (pretrained on ImageNet)\n",
    "# https://pytorch.org/vision/main/models/vision_transformer.html\n",
    "# https://huggingface.co/docs/transformers/main/en//model_doc/vit\n",
    "class AgeEstimationViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AgeEstimationViT, self).__init__()\n",
    "        self.vit = create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=0) #remove classifier head\n",
    "\n",
    "        in_features = self.vit.num_features\n",
    "\n",
    "        #regression head\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit.forward_features(x) #image passed through model to extract features\n",
    "        x = x[:,0] #first token (represents whole image) is selected\n",
    "        x = self.regressor(x) #this token is passed through regression head which processes the features and returns age prediction\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "f16db90ad8404763b0f1076ddf5d2572",
      "212514058e8e4d718145a846e0ce92be",
      "d28c859c89ee4b139737b983d543ae00",
      "1a28fe071a404d299de16ab95b3a7cbe",
      "eaa58a0a30ce4aa2a56c859890974ae7",
      "cb78b3cae06e4823891b21f011e61c72",
      "c423e5a5466a4e1fae38a9ff30d09a82",
      "bc23ff41daf24d55ad28f1be5560694e",
      "982795c0f46a46dfbcf5cf1f3da50088",
      "d6bffa64fb31483099c12506777a2d36",
      "4df9656338284983bd9dbc8c97221c44"
     ]
    },
    "id": "ZhMAxeL2pXn8",
    "outputId": "f7560256-3fbe-48d6-b61f-c2e83aec2622"
   },
   "outputs": [],
   "source": [
    "# creating the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AgeEstimationViT().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6twHGx4MLcR",
    "outputId": "957a0a5f-e80d-471f-e304-efe50b6cd3bd"
   },
   "outputs": [],
   "source": [
    "# print model summary\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 3, 224, 224))  # Adjust based on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeulEpeMNjkc"
   },
   "outputs": [],
   "source": [
    "# Function to plot training curves\n",
    "def plot_training_curves(train_losses, val_losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2TSahqb7GOr"
   },
   "source": [
    "### Defining the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQIJIX4r3Law"
   },
   "outputs": [],
   "source": [
    "# Training function with early stopping and model saving\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, patience, model_path):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stopping_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            with tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Epoch {epoch+1}\") as t:\n",
    "                for inputs, labels, _ in t:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs.view_as(labels), labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.6f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    early_stopping_counter = 0\n",
    "                    # Save best model during training\n",
    "                    print(\"saving best model...\")\n",
    "                    torch.save(best_model_wts, model_path)\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                    if early_stopping_counter >= patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        plot_training_curves(train_losses, val_losses)\n",
    "                        return model\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plot_training_curves(train_losses, val_losses)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2esCEOqN4tTH"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7gzC_atC4sGS",
    "outputId": "4f189d1b-e6f0-46a3-dbda-3ccacca30c75"
   },
   "outputs": [],
   "source": [
    "#==================\n",
    "MODEL_TRAIN = True\n",
    "#==================\n",
    "\n",
    "# model hyperparameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2)\n",
    "num_epochs = 10\n",
    "patience = 10\n",
    "\n",
    "# data loaders\n",
    "dataloaders = {\"train\": aug_dataloader_train, \"val\": dataloader_valid}  # Assuming split dataset\n",
    "\n",
    "if (MODEL_TRAIN):\n",
    "  #if(MOUNT_GOOGLE_DRIVE):\n",
    "    #best_model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, patience,\"/content/best_age_estimation_model.pth\")\n",
    "  best_model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, patience,\"best_age_estimation_model.pth\")\n",
    "else:\n",
    "  # download the pretrained model\n",
    "  !wget http://data.chalearnlap.cvc.uab.cat/Colab_MFPDS/2025/best_age_estimation_model.zip\n",
    "\n",
    "  # decompressing the data\n",
    "  from zipfile import ZipFile\n",
    "\n",
    "  with ZipFile('best_age_estimation_model.zip','r') as zip:\n",
    "    zip.extractall()\n",
    "    print('Model decompressed successfully')\n",
    "\n",
    "  # removing the .zip file after extraction to clean space\n",
    "  !rm best_age_estimation_model.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T14U_WEQ3iRo"
   },
   "source": [
    "# Making predictions on Validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuRHMRwKgK5N"
   },
   "outputs": [],
   "source": [
    "# Function to make predictions on test set and compute MSE\n",
    "def predict_and_evaluate(model_path, test_dataset, batch_size=32, output_csv=\"predictions.csv\", output_zip=\"predictionsViTbaseline.zip\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AgeEstimationViT().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    predictions = []\n",
    "    actual_ages = []\n",
    "    metadatas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, metadata in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).squeeze().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            predictions.extend(outputs*test_dataset.__normalization_factor__())\n",
    "            actual_ages.extend(labels*test_dataset.__normalization_factor__())\n",
    "\n",
    "        for idx in tqdm(range(len(test_dataset))):\n",
    "            image, age, metadata = test_dataset[idx]\n",
    "            metadata = test_dataset.data_info.iloc[idx, 2:].tolist()\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "    mae = np.mean(np.abs(np.array(predictions) - np.array(actual_ages)))\n",
    "    print(f\"\\n=======\\nMean Absolute Error on Test Set: {mae:.4f}\")\n",
    "\n",
    "    # Save only predictions to CSV without headers\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for pred in predictions:\n",
    "            writer.writerow([pred])\n",
    "\n",
    "    # Zip the CSV file using ZipFile\n",
    "    with ZipFile(output_zip, 'w') as zipf:\n",
    "        zipf.write(output_csv, os.path.basename(output_csv))\n",
    "\n",
    "    print(f\"Predictions saved to {output_csv} and compressed as {output_zip}\")\n",
    "\n",
    "    return predictions, actual_ages, mae, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AdyHGi-Lrat"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTn9V-klNqsv",
    "outputId": "b801145a-b0e3-4865-bba3-f9811bd2a36b"
   },
   "outputs": [],
   "source": [
    "!wget http://data.chalearnlap.cvc.uab.cat/Colab_MFPDS/bias_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8DoQDhANG1U"
   },
   "outputs": [],
   "source": [
    "from bias_functions import age_bias, gender_bias, ethnicity_bias, face_expression_bias\n",
    "\n",
    "def calculate_bias(model, dataset, predictions, actual_ages, metadata):\n",
    "    # Calculate bias scores\n",
    "    age_bias(predictions, actual_ages)\n",
    "    gender_bias(predictions, actual_ages, metadata)\n",
    "    ethnicity_bias(predictions, actual_ages, metadata)\n",
    "    face_expression_bias(predictions, actual_ages, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J42UW8C-3jrB"
   },
   "outputs": [],
   "source": [
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bpuqWTG3vKt",
    "outputId": "005eda7c-d2ef-4f94-d98f-9804ad5279e3"
   },
   "outputs": [],
   "source": [
    "predictions_val, actual_ages_val, mae_val, metadata_val = predict_and_evaluate(\"/content/best_age_estimation_model.pth\", dataset_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYc0Qg_f4Jjv",
    "outputId": "5615a893-0e78-4e1a-bd43-9739acfaafa1"
   },
   "outputs": [],
   "source": [
    "calculate_bias(\"/content/best_age_estimation_model.pth\", dataset_valid, predictions_val, actual_ages_val, metadata_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3Kw0er2gGtO"
   },
   "source": [
    "# Making predictions on Test set\n",
    "The following cells are generating predictions (and evaluating them) on the **Test set** so that we can create our submission file to be uploaded to our age estimation challenge. **IMPORTANT:** <font color='red'>**Do not evaluate your model on the Test set when defining your training strategy, model or hyperparameters.</font> For this, use the Validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddeifRIUg4lK"
   },
   "outputs": [],
   "source": [
    "# Create dataset and dataloader (test set):\n",
    "dataset_test = AgeEstimationDataset(\"test_data\", \"labels_metadata_test.csv\", transform=data_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQMhBpfSgxcZ",
    "outputId": "03245054-0fe1-4a4b-dcff-ef690faafef3"
   },
   "outputs": [],
   "source": [
    "predictions, actual_ages, mae, metadata = predict_and_evaluate(\"/content/best_age_estimation_model.pth\", dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJ-kk0tANd1y",
    "outputId": "b147f9f3-8544-496b-8eb5-11c7c188ac0b"
   },
   "outputs": [],
   "source": [
    "calculate_bias(\"/content/best_age_estimation_model.pth\", dataset_test, predictions, actual_ages, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O36-cncBOS2t"
   },
   "source": [
    "#Custom Loss (non-augmented data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqLZU710gOjW"
   },
   "outputs": [],
   "source": [
    "class AgeEstimationDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.age_normalization_factor = 100; # used to normalize age labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __normalization_factor__(self):\n",
    "        return self.age_normalization_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = f\"{self.data_info.iloc[idx, 0]:06d}.jpg\"  # Format image ID\n",
    "        image_path = os.path.join(self.image_dir, image_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\n",
    "        # normalizing age labes (by 100) to be between 0 and 1 (assuming 100 is the max age)\n",
    "        age = float(self.data_info.iloc[idx, 1])/self.age_normalization_factor  # Load age label\n",
    "        metadata = self.data_info.iloc[idx, 2:].tolist()  # Extract metadata as list\n",
    "        ethnicity = self.data_info.iloc[idx, 2]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(age, dtype=torch.float32), metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOb9HV9NgTn4"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ufe0PxkqgZVi",
    "outputId": "617ef6e2-e5e6-41ba-835e-460241de4ccc"
   },
   "outputs": [],
   "source": [
    "# Create dataset and dataloader (train set):\n",
    "dataset_train = AgeEstimationDataset(\"train_data\", \"labels_metadata_train.csv\", transform=data_transforms)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of train samples: {len(dataloader_train.dataset)}\")\n",
    "\n",
    "# Create dataset and dataloader (validation set):\n",
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of valid samples: {len(dataloader_valid.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyUxNR1n1kGf",
    "outputId": "f287017d-e131-42a4-a691-aa5d96506bf6"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels_metadata_train.csv\")\n",
    "print(df['ethnicity'].value_counts())  # Check the distribution of ethnicity in the original dataset\n",
    "print(df['gender'].value_counts())\n",
    "print(df['emotion'].value_counts())\n",
    "over_60_count = df[df['age'] > 60].shape[0]\n",
    "print(f\"Number of people over 60: {over_60_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKAFP2Ep0nRD"
   },
   "outputs": [],
   "source": [
    "group_counts = {'caucasian' : 3522, 'asian' : 424, 'afroamerican' : 119, 'male' : 2068, 'female' : 1997, 'slightlyhappy' : 1784, 'neutral' : 1404, 'happy' : 712, 'other' : 165}\n",
    "#group_labels = ['caucasian','asian', 'afroamerican', 'male', 'female', 'slightlyhappy', 'neutral', 'happy', 'other']\n",
    "\n",
    "def customized_mse_loss_batch(y_true, y_pred, group_counts, metadata):\n",
    "    \"\"\"\n",
    "    Customized MSE loss that assigns higher weight to underrepresented groups.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Tensor of true values (e.g., true ages) of shape (batch_size,)\n",
    "    - y_pred: Tensor of predicted values (e.g., predicted ages) of shape (batch_size,)\n",
    "    - group_labels: Tensor or list of group labels corresponding to each sample in the batch\n",
    "    - group_counts: Dictionary with counts of each group in the entire dataset\n",
    "\n",
    "    Returns:\n",
    "    - Weighted MSE loss for the batch\n",
    "    \"\"\"\n",
    "    # Convert to float if necessary\n",
    "    y_true = y_true.float()\n",
    "    y_pred = y_pred.float()\n",
    "\n",
    "    # Compute the Mean Squared Error (MSE) loss for each sample\n",
    "    mse_loss = (y_pred - y_true) ** 2\n",
    "\n",
    "    # Create a weight vector based on the group frequencies (inverse frequency weighting)\n",
    "    # give higher weights to underrepresented groups\n",
    "    group_weights = []\n",
    "    #for label in group_labels:\n",
    "    for i in range(len(metadata[0])):\n",
    "        label = metadata[1][i]\n",
    "        group_size = group_counts.get(label, 1)  # Use 1 to avoid division by zero\n",
    "        group_weight = 1 / group_size  # Inverse of the frequency (lower frequency -> higher weight)\n",
    "        group_weights.append(group_weight)\n",
    "\n",
    "    # Convert group_weights to a tensor\n",
    "    weight_vec = torch.tensor(group_weights, dtype=torch.float32, device = y_true.device)\n",
    "\n",
    "    # Apply the weight to the MSE loss\n",
    "    weighted_mse_loss = mse_loss * weight_vec\n",
    "\n",
    "    # Return the mean of the weighted loss\n",
    "    return weighted_mse_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8GnccJkTdy4"
   },
   "outputs": [],
   "source": [
    "#train model with custom loss that accounts for both age and ethnicity weights\n",
    "def train_model_with_custom_loss(model, dataloaders, optimizer, scheduler, num_epochs, patience, model_path):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stopping_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_threshold = 3\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            with tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Epoch {epoch+1}\") as t:\n",
    "\n",
    "                for inputs, labels, metadata in t:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    genders = metadata[0]\n",
    "                    ethnicities = metadata[1]\n",
    "                    expressions = metadata[2]\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if isinstance(ethnicities, tuple):\n",
    "                        ethnicities = list(ethnicities)\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                        # Calculate sample weights based on age and ethnicity\n",
    "                        #sample_weights = calculate_sample_weights(labels.cpu().detach().numpy(), ethnicities, expressions, genders, 4)\n",
    "\n",
    "                        #print(f'Sample Weights: {sample_weights}')\n",
    "\n",
    "                        #sample_weights = torch.tensor(sample_weights, dtype=torch.float32, device=inputs.device)\n",
    "\n",
    "                        # Calculate weighted MSE loss\n",
    "                        loss = customized_mse_loss_batch(labels, outputs.view_as(labels), group_counts, metadata)\n",
    "                        #loss = weighted_mse_loss(outputs.view_as(labels), labels, sample_weights)\n",
    "                        # Apply custom loss starting from a certain epoch\n",
    "\n",
    "                        '''if epoch > epoch_threshold:\n",
    "                            # Custom loss applied after epoch_threshold\n",
    "                            loss = customized_mse_loss_batch(labels, outputs.view_as(labels), group_labels, group_counts)\n",
    "                        else:\n",
    "                            # Default loss (e.g., MSE) before epoch_threshold\n",
    "                            loss = criterion(outputs.view_as(labels), labels)'''\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.6f}')\n",
    "\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "                # Save the best model during training\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    early_stopping_counter = 0\n",
    "                    print(\"Saving best model...\")\n",
    "                    torch.save(best_model_wts, model_path)\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                    if early_stopping_counter >= patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        plot_training_curves(train_losses, val_losses)\n",
    "                        return model\n",
    "\n",
    "\n",
    "    print(f'Predictions: {outputs}, Labels: {labels}')\n",
    "    # Load best model weights and plot training curves\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plot_training_curves(train_losses, val_losses)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oy9jn9n0f1MI",
    "outputId": "c031160c-13ad-4bc3-cbcb-5e7a8c2b2415"
   },
   "outputs": [],
   "source": [
    "#==================\n",
    "MODEL_TRAIN = True\n",
    "#==================\n",
    "\n",
    "# model hyperparameters\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2)\n",
    "num_epochs =10\n",
    "patience = 10\n",
    "\n",
    "# data loaders\n",
    "dataloaders = {\"train\": dataloader_train, \"val\": dataloader_valid}  # Assuming split dataset\n",
    "\n",
    "if (MODEL_TRAIN):\n",
    "  #if(MOUNT_GOOGLE_DRIVE):\n",
    "    #best_model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, patience,\"/content/best_age_estimation_model.pth\")\n",
    "  best_model = train_model_with_custom_loss(model, dataloaders, optimizer, scheduler, num_epochs, patience,\"best_age_estimation_model_customloss.pth\")\n",
    "else:\n",
    "  # download the pretrained model\n",
    "  !wget http://data.chalearnlap.cvc.uab.cat/Colab_MFPDS/2025/best_age_estimation_model.zip\n",
    "\n",
    "  # decompressing the data\n",
    "  from zipfile import ZipFile\n",
    "\n",
    "  with ZipFile('best_age_estimation_model_customloss.zip','r') as zip:\n",
    "    zip.extractall()\n",
    "    print('Model decompressed successfully')\n",
    "\n",
    "  # removing the .zip file after extraction to clean space\n",
    "  !rm best_age_estimation_model.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQJiOpFt42NE"
   },
   "source": [
    "# Making predictions on Validation set (w/ custom loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KtnUqrxDyDG"
   },
   "outputs": [],
   "source": [
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWLQsNpgDzyF",
    "outputId": "b23c6166-26be-4f05-9a31-a9495df7eb13"
   },
   "outputs": [],
   "source": [
    "predictions_val, actual_ages_val, mae_val, metadata_val = predict_and_evaluate(\"/content/best_age_estimation_model_customloss.pth\", dataset_valid)\n",
    "print(predictions_val)\n",
    "print(actual_ages_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlCQdGy94zv6",
    "outputId": "bdda2b00-2419-4ed9-db35-9dde303b15e1"
   },
   "outputs": [],
   "source": [
    "calculate_bias(\"/content/best_age_estimation_model_customloss.pth\", dataset_valid, predictions_val, actual_ages_val, metadata_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUbodKWhB3Sv"
   },
   "source": [
    "# Making predictions on Test set (custom loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8udfL4lvB2pq"
   },
   "outputs": [],
   "source": [
    "dataset_test = AgeEstimationDataset(\"test_data\", \"labels_metadata_test.csv\", transform=data_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpwirzAuB-Um",
    "outputId": "d6c487cc-0265-42b4-8313-df78e544201f"
   },
   "outputs": [],
   "source": [
    "predictions, actual_ages, mae, metadata = predict_and_evaluate(\"/content/best_age_estimation_model_customloss.pth\", dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P_ij7_8CG46",
    "outputId": "9b95ba74-673d-4ddb-f12b-a7ee8723d22c"
   },
   "outputs": [],
   "source": [
    "calculate_bias(\"/content/best_age_estimation_model_customloss.pth\", dataset_test, predictions, actual_ages, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neNuM8cJLpSb"
   },
   "source": [
    "#Custom Loss with augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v8gkaTSL9eM"
   },
   "source": [
    "#Augmentating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AOVxiooL80j",
    "outputId": "a323f155-3031-4cc9-b2d6-1347e63f9a2a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm  # for progress bar (optional)\n",
    "import torch\n",
    "\n",
    "class AgeEstimationDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None, augmentation_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.augmentation_transform = augmentation_transform  # Optional augmentation transform\n",
    "        self.age_normalization_factor = 100  # Used to normalize age labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __normalization_factor__(self):\n",
    "        return self.age_normalization_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = f\"{self.data_info.iloc[idx, 0]:06d}.jpg\"  # Format image ID\n",
    "        image_path = os.path.join(self.image_dir, image_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Load image as RGB\n",
    "\n",
    "        # Normalize age labels (by 100) to be between 0 and 1 (assuming 100 is the max age)\n",
    "        age = float(self.data_info.iloc[idx, 1]) / self.age_normalization_factor  # Load age label\n",
    "        metadata = self.data_info.iloc[idx, 2:].tolist()  # Extract metadata as list\n",
    "        ethnicity = metadata[1]\n",
    "        age_value = int(self.data_info.iloc[idx, 1])\n",
    "\n",
    "        # Apply augmentation based on conditions (ethnicity or age > 60)\n",
    "        if (ethnicity in ['afroamerican', 'asian']) or (age_value > 60):\n",
    "            if self.augmentation_transform:\n",
    "                image = self.augmentation_transform(image)\n",
    "\n",
    "        # Apply any additional transforms (like normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(age, dtype=torch.float32), metadata\n",
    "\n",
    "\n",
    "def save_augmented_images_and_update_csv(dataset, augmentation_transforms, output_dir, csv_file, num_augmented_images=3):\n",
    "    # Create a new directory for augmented images\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the original CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "    # Augment and save images\n",
    "    augmented_data = []\n",
    "    for idx in tqdm(range(len(dataset)), desc=\"Processing images\"):\n",
    "        image, age, metadata = dataset[idx]  # Get the original image and other data\n",
    "        original_image_id = dataset.data_info.iloc[idx, 0]\n",
    "        metadata = dataset.data_info.iloc[idx, 2:].tolist()\n",
    "        gender = metadata[0]\n",
    "        ethnicity = metadata[1]\n",
    "        expression = metadata[2]\n",
    "        age_value = int(dataset.data_info.iloc[idx, 1])\n",
    "\n",
    "        # Apply augmentation only if the condition is met (ethnicity or age > 60)\n",
    "        if (ethnicity in ['afroamerican', 'asian']) or (age_value > 60):\n",
    "            # Apply augmentation multiple times (num_augmented_images times)\n",
    "            for i in range(num_augmented_images):\n",
    "                augmented_image = augmentation_transforms(image)  # Apply the augmentation\n",
    "\n",
    "                augmented_image_pil = transforms.ToPILImage()(augmented_image)\n",
    "\n",
    "                # Save the augmented image\n",
    "                augmented_image_name = f\"augmented_{original_image_id}_{i}.jpg\"\n",
    "                new_image_path = os.path.join(output_dir, augmented_image_name)\n",
    "                augmented_image_pil.save(new_image_path)\n",
    "\n",
    "                # Add new entry to augmented data\n",
    "                #augmented_data.append([original_image_id, age.item()] + [metadata] + [new_image_path])\n",
    "                augmented_data.append([original_image_id, age.item()*100, gender, ethnicity, expression])\n",
    "\n",
    "\n",
    "    # Append the augmented data to the original dataframe\n",
    "    augmented_df = pd.DataFrame(augmented_data, columns=df.columns.tolist())\n",
    "\n",
    "    # Append to the original CSV file without overwriting it\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "    else:\n",
    "        # If file exists, append to a new file to avoid overwriting\n",
    "        new_csv_file = f\"augmented_{os.path.basename(csv_file)}\"\n",
    "        df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "        df.to_csv(new_csv_file, index=False)\n",
    "        print(f\"CSV file already exists. Augmented data saved to new file: {new_csv_file}\")\n",
    "\n",
    "    print(f\"CSV file updated with augmented images: {csv_file}\")\n",
    "\n",
    "\n",
    "# Define the augmentation transforms\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "])\n",
    "\n",
    "# Define the standard transforms for all data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Assume the original dataset and transform\n",
    "dataset_train = AgeEstimationDataset(\n",
    "    image_dir=\"train_data\",  # Directory where original images are stored\n",
    "    csv_file=\"labels_metadata_train.csv\",  # Original CSV file\n",
    "    transform=data_transforms['train'],  # You can apply the transforms to training data here\n",
    "    augmentation_transform=None  # Augmentation transform will be applied conditionally in the `__getitem__` method\n",
    ")\n",
    "\n",
    "# Directory to save augmented images\n",
    "output_dir = \"augmented_train_data\"\n",
    "\n",
    "# Number of augmented images to generate per original image\n",
    "num_augmented_images = 3  # For example, generate 3 augmented images for each original image\n",
    "\n",
    "# Update CSV with augmented images\n",
    "save_augmented_images_and_update_csv(dataset_train, augmentation_transforms, output_dir, \"labels_metadata_train.csv\", num_augmented_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWtV_9o7MKU9",
    "outputId": "d8488273-78b4-45b7-93da-e05bb58a2b3d"
   },
   "outputs": [],
   "source": [
    "# Create dataset and dataloader (train set):\n",
    "aug_dataset_train = AgeEstimationDataset(\"train_data\", \"augmented_labels_metadata_train.csv\", transform=data_transforms['train'])\n",
    "aug_dataloader_train = DataLoader(aug_dataset_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of train samples: {len(aug_dataloader_train.dataset)}\")\n",
    "\n",
    "# Create dataset and dataloader (validation set):\n",
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms['val'])\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True, num_workers=2)\n",
    "print(f\"Total number of valid samples: {len(dataloader_valid.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VLffMUDdMSdi",
    "outputId": "bf89abb8-9eeb-45d7-d4dc-6068b9ce57f7"
   },
   "outputs": [],
   "source": [
    "#==================\n",
    "MODEL_TRAIN = True\n",
    "#==================\n",
    "\n",
    "# model hyperparameters\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2)\n",
    "num_epochs =10\n",
    "patience = 10\n",
    "\n",
    "# data loaders\n",
    "dataloaders = {\"train\": aug_dataloader_train, \"val\": dataloader_valid}  # Assuming split dataset\n",
    "\n",
    "if (MODEL_TRAIN):\n",
    "  #if(MOUNT_GOOGLE_DRIVE):\n",
    "    #best_model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, patience,\"/content/best_age_estimation_model.pth\")\n",
    "  best_model = train_model_with_custom_loss(model, dataloaders, optimizer, scheduler, num_epochs, patience,\"best_age_estimation_model_customloss_augmentations.pth\")\n",
    "else:\n",
    "  # download the pretrained model\n",
    "  !wget http://data.chalearnlap.cvc.uab.cat/Colab_MFPDS/2025/best_age_estimation_model.zip\n",
    "\n",
    "  # decompressing the data\n",
    "  from zipfile import ZipFile\n",
    "\n",
    "  with ZipFile('best_age_estimation_model_customloss_augmenations.zip','r') as zip:\n",
    "    zip.extractall()\n",
    "    print('Model decompressed successfully')\n",
    "\n",
    "  # removing the .zip file after extraction to clean space\n",
    "  !rm best_age_estimation_model.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM2KGkx9Lwv0"
   },
   "source": [
    "# Making predictions on Validation set (w/ custom loss and augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg_vr3IYQgdU"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LdfuWdoLwv1"
   },
   "outputs": [],
   "source": [
    "dataset_valid = AgeEstimationDataset(\"valid_data\", \"labels_metadata_valid.csv\", transform=data_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LmyOPWILwv1",
    "outputId": "45250a27-3dc4-4d51-c2f5-6040109eee5d"
   },
   "outputs": [],
   "source": [
    "predictions_val, actual_ages_val, mae_val, metadata_val = predict_and_evaluate(\"/content/best_age_estimation_model_customloss_augmentations.pth\", dataset_valid)\n",
    "print(predictions_val)\n",
    "print(actual_ages_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZcGjxwBLwv2",
    "outputId": "367e419a-59f7-4084-f673-ba0bee62ff2e"
   },
   "outputs": [],
   "source": [
    "calculate_bias(\"/content/best_age_estimation_model_customloss_augmentations.pth\", dataset_valid, predictions_val, actual_ages_val, metadata_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWaUY-oULwv2"
   },
   "source": [
    "# Making predictions on Test set (custom loss and augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUV2Q9QELwv2"
   },
   "outputs": [],
   "source": [
    "dataset_test = AgeEstimationDataset(\"test_data\", \"labels_metadata_test.csv\", transform=data_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gW7FJgB-Lwv3",
    "outputId": "30cbc0ec-a7f6-44cc-f1c6-8c75e99f50ee"
   },
   "outputs": [],
   "source": [
    "predictions, actual_ages, mae, metadata = predict_and_evaluate(\"/content/best_age_estimation_model_customloss_augmentations.pth\", dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnwuqQSqLwv3",
    "outputId": "bbc88cb4-c4a1-4c40-aaa7-934e99e2651b"
   },
   "outputs": [],
   "source": [
    "calculate_bias(\"/content/best_age_estimation_model_customloss_augmentations.pth\", dataset_test, predictions, actual_ages, metadata)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
